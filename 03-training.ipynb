{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e95de7-7801-401d-b098-fee169c373a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch.cuda import empty_cache\n",
    "from torch.nn import Linear, CrossEntropyLoss\n",
    "from torch.optim import AdamW, Adam\n",
    "from torch.optim.lr_scheduler import StepLR \n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "from data_utils import label2id, id2label\n",
    "from datasets import load_from_disk\n",
    "from model import get_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d7126b-2e19-4dd7-ad2b-11cce959e81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_from_disk('./data/processed/dataset_3/')\n",
    "train, val = data['train'], data['val']\n",
    "\n",
    "print(len(train), len(val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a4bb97-78d5-46a8-aa5c-0cbc086e92b6",
   "metadata": {},
   "source": [
    "## PyTorch Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4239cce-aa94-4d49-bb6e-94c4959a0893",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model, tokenizer = get_model('sileod/deberta-v3-large-tasksource-nli')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a4d38a-00db-48ee-8151-cdbaf82377e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.config.num_labels = 15\n",
    "model.config.id2label = id2label\n",
    "model.config.label2id = label2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dde356b-c528-496e-bd51-51ab7684f4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(list(label2id.keys()))\n",
    "classifier_layer = torch.nn.Linear(model.classifier.in_features, num_classes, dtype=torch.bfloat16).to('cuda')\n",
    "\n",
    "model.classifier = classifier_layer\n",
    "model.num_labels = num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8fcb615-6332-4047-9a10-f5cfb0bd0b3e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Freeze complete model\n",
    "for layer in model.parameters():\n",
    "    layer.requires_grad = False\n",
    "\n",
    "# Unfreeze last 6 encoder layers\n",
    "for layer in model.deberta.encoder.layer[-6:].parameters():\n",
    "    layer.requires_grad = True\n",
    "\n",
    "# Unfreeze the classifier\n",
    "for layer in model.classifier.parameters():\n",
    "    layer.requires_grad = True\n",
    "\n",
    "# Print name of the layers that are unfrozen\n",
    "for name, layer in model.named_parameters():\n",
    "    if layer.requires_grad == True:\n",
    "        print(name, layer.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fa558a-f15d-4426-994f-c02fc087ebf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 50\n",
    "learning_rate = 1e-4\n",
    "batch_size=16\n",
    "\n",
    "optimizer = Adam(model.parameters(), lr=learning_rate)\n",
    "scheduler = StepLR(optimizer, step_size=5, gamma=0.1, verbose=True)\n",
    "total_steps = len(train) * num_epochs\n",
    "\n",
    "device = 'cuda'\n",
    "loss_fn = CrossEntropyLoss(\n",
    "    weight=torch.tensor([1, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100]).to('cuda', dtype=torch.bfloat16),\n",
    "    label_smoothing=0.05\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30c9961-9297-4345-8344-ace2898d19aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stack(x, p=0): return pad_sequence([torch.tensor(t) for t in x], True, padding_value=p)\n",
    "def get_tensor_size(tensor): return tensor.element_size() * tensor.nelement()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8ce099-392a-4fd1-b0a0-2b18cb1282c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_losses = []\n",
    "model.train()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    with tqdm(total=len(train)//batch_size, desc=f'Epoch {epoch+1}/{num_epochs}') as pbar:\n",
    "        for s in range(0, len(train), batch_size):\n",
    "            optimizer.zero_grad()\n",
    "            batch = train[s:s+batch_size]\n",
    "            \n",
    "            input_ids = stack(batch['input_ids']).to(device)\n",
    "            attention_mask = stack(batch['attention_mask']).to(device)\n",
    "            labels = stack(batch['labels']).to(device)\n",
    "    \n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "    \n",
    "            loss = loss_fn(\n",
    "                outputs.logits.reshape(len(labels), 15, stack(batch['labels']).shape[-1]),\n",
    "                labels\n",
    "            )\n",
    "            \n",
    "            all_losses.append(loss)\n",
    "            loss.backward()\n",
    "    \n",
    "            optimizer.step()\n",
    "\n",
    "            pbar.set_postfix({'Loss': f'{loss.item():.4f}'})\n",
    "            pbar.update(1)\n",
    "\n",
    "            empty_cache()\n",
    "\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae4509c-74b6-411c-8824-79a73f67923e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch['attention_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f41d6fc-57c4-4d4f-9077-fbb7a460e042",
   "metadata": {},
   "outputs": [],
   "source": [
    "stack(batch['labels']).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48bef6fb-4269-4385-8522-5864c8592af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch['labels'][0].__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0ec686-e878-4900-a2fc-063d38f8df3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs.logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018af4e8-57d7-4673-85a3-24092ec04851",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_losses = [a.detach().to('cpu', torch.float16).numpy() for a in all_losses]\n",
    "plt.plot(all_losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f552cca-a5c8-4584-9a25-dffe91e2f602",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(trained_model, eval_dataset, bs):\n",
    "    label_metrics = dict.fromkeys(label2id.values())\n",
    "    for k, v in label_metrics.items():\n",
    "        label_metrics[k] = {'total_samples': 0, 'total_predicted': 0, 'correct_predictions': 0}\n",
    "\n",
    "    trained_model.eval()\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for s in tqdm(range(0, len(eval_dataset), bs)):\n",
    "            batch = eval_dataset[s:s+bs]\n",
    "            \n",
    "            input_ids = stack(batch['input_ids']).to(device)\n",
    "            attention_mask = stack(batch['attention_mask']).to(device)\n",
    "            labels = stack(batch['labels'], -100).to(device)\n",
    "            \n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            \n",
    "            _, predicted_labels = torch.max(outputs.logits, -1)\n",
    "    \n",
    "            for p, l in zip(predicted_labels.flatten(), labels.flatten()):\n",
    "                \n",
    "                if l == -100:\n",
    "                    continue\n",
    "    \n",
    "                if p==l:\n",
    "                    correct_predictions +=1\n",
    "                    label_metrics[l.item()]['correct_predictions'] += 1\n",
    "    \n",
    "                label_metrics[l.item()]['total_samples'] += 1\n",
    "                label_metrics[p.item()]['total_predicted'] += 1\n",
    "    \n",
    "                total_samples +=1\n",
    "\n",
    "    return pd.DataFrame.from_records(label_metrics).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef97523-ecb6-436f-9658-dbea7d5b6960",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "train_metrics = eval_model(model, train, 256)\n",
    "val_metrics = eval_model(model, val, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9a1867-ac8f-4514-96d1-e9d2d2ccc063",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c19b9a-37bd-482f-8330-f1c4112b96c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = val_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754cf9ad-0bca-464b-ad69-11ed10d36e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = 100*df.correct_predictions/df.total_predicted\n",
    "recall = 100*df.correct_predictions/df.total_samples\n",
    "f5 = 36 * precision*recall/(5*precision+recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63cf9456-389a-4e55-8377-df4c2b194b9b",
   "metadata": {},
   "source": [
    "Rough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a00089-4377-4094-9b88-f78c5e4db148",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = tokenizer('romit', return_tensors='pt')\n",
    "tempop = model(temp['input_ids'].to('cuda'))\n",
    "torch.max(tempop.logits, -1)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6efd03d5-0729-42fa-990a-e40ff40fcf37",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "[id2label[t] if t != -100 else None for t in train[0]['labels']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9504b60b-dc38-41dd-83e7-0e1203100efe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "[id2label[t.to('cpu').item()] for t in torch.max(op.logits[0], -1)[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc652d0-b8d2-4641-bf8e-00b1895dfedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Smaller sequences\n",
    "# [X] Different model\n",
    "# [X] Write test case for validating data\n",
    "# [X] Data augmetation\n",
    "# Resampling data?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
